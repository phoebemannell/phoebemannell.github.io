---
layout: post
title: Command Line and Regular Expressions
---

**Intro to Bash Command Line and Counting and Mining Research Data with Unix**

The Bash Command Line tutorial probably should have been tutorial #1. Oh my god my life would have been so much easier if I had learned these things systematically at an earlier point. I know Shawn has already stated that he meant to have this earlier in the lesson plan, but it is definitely a necessary opening lesson for those planning on working in digital history. 

Using terminal is like crafting a custom cabinet. It would be easier and faster to go to IKEA, buying a dresser, and assembling it in an afternoon, but if you built your own from scratch, it would end up being custom-built for your needs, would be stronger and last longer, and is probably a better product. But if you mess up assembling an IKEA dresser, worst case scenario you've wasted a few hundred dollars and an afternoon. If you mess up working on your custom cabinet, you've wasted tons of time, materials, money, and you're definitley extremely frustrated. But there are also workarounds when you mess it up, and you can replace a piece rather than replacing an entire piece of furniture which is necessary when your IKEA dresser inevitably crumbles into its constituent pulp. 

Using command line is powerful, and you get to know the ways that your computer is operating in a way that is inaccessible if you stay in the GUI. Things that seem impossible or deeply complex when you try to do them through a software tool might be extremely easy using the command line. Though this may run the other way, as well. So it is imperative that when deciding which route you are going to take (whether we're heading to IKEA or to the lumber yard) that you consider WHY you are choosing that route, and whether it is going to serve your long-term purposes. 

Because sometimes you just need to grab an endtable to toss in the guest bedroom because Mom is coming to visit and something is better than nothing and like heck you're going to build something half-decent from scratch before Friday. 

**Understanding Regular Expressions**

The goal of this tutorial from Programming Historian is to introduce people to the use of RegEx language in cleaning up and organizing raw 'prose' data into tabular or comma-separated formats. It is a necessary step for doing any kind of meta-analysis of the contents of the archival documents, as it is this creation of inter-related columns and rows that will allow other analytic tools to 

On a mac (and also on windows, I realized in class when we discussed the tutorial), replacing <$> with <nothing> turned the document into one single line, not many single lines for each paragraph health record. There is something about this command that does not work properly, as it does not create the indicated specific outcome that the writer indicates should occur. The solution I have come up with is that having run and re-run the command (and trying my best to edit it and change it to try to get the desired outcome), the best I can do is to go through the document and insert line breaks where they should be based on the original text. Tedious. 

And now, several replaces down the line, I've gotten to the ^([A-Za-z .]+\t<t>) replace and I am finding nothing. Copy and pasting the entire text into the spreadsheet does not show the third column for some lines as it does in the tutorial. I have no idea why not. And that is really frustrating. I want to understand what I've done and how and why I've done it. The tutorial does say that this tutorial is to give you a taste of what RegEx can do, rather than give you knowledge of the entire complex language, and I deeply appreciate the glossary of what each of the symbols do. But this is an alphabet, not a language, and understanding how they all link together to form a useful phrase that can help find, locate, and organize the information from your archive is far more complex. They did give us building blocks, and from there we could return to our personal corpus of text to work with. 

I did appreciate that it was apparent that the writers were intimately familiar with the archival materials, but this should be more blatantly discussed, because the way that a digital historian is going to approach their data will be shaped *most* by the archival material itself. This is not discussed sufficiently in the tutorial. 

**I come back to this now, at the turn of the tide!**

Having used both command line tools and Regular Expressions in the prep work for my final project for this class, I returned to these tutorials quite a few times, especially when we were trying to work out original regular expressions that would meet the criteria for a text that is quite long and messy (in terms of repeated phrases). It was frustrating that we felt we had to work from scratch, despite having both this tutorial and several other online resources. When I initially went through this tutorial, I felt frustrated that one step wasn't working for me and that I didn't understand how to fix what was going wrong. The fairly easy (though pedagogically useless) solution was that I went through the file by hand, and I knew that when creating a tutorial for others, who might get frustrated at such a tedious step and give up, that this sort of fix just wouldn't fly. We needed better solutions, *especially* if the express goal is to get historians to try these tools out on their own data. 

What we decided on was transparancy. In our final project we are going to discuss these issues, and supply a meta-narrative of how we dealt with *building* the tutorial, and the struggles we went through trying to get a tutorial to apply to an entirely different file which was probably OCR'd by a different program and had unique issues with text recognition. And while we do not have the capability to explain the RegEx phrases we designed, we can link our 'students' to tutorials like these, and others, that helped US figure out what WE were doing, so that they do not have to go searching quite so far to find their own solutions. 
